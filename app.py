import io
import json
import os
import traceback
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st
from google import genai

# ==============================================================================
# 1. ìœ í‹¸ë¦¬í‹° & í—¬í¼ í•¨ìˆ˜
# ==============================================================================


def read_excel_sheets(uploaded_file) -> Dict[str, pd.DataFrame]:
    """ì—‘ì…€ íŒŒì¼ì„ ì½ì–´ {sheet_name: df} í˜•íƒœë¡œ ë°˜í™˜ (í—¤ë” ì—†ì´ raw read)"""
    file_bytes = uploaded_file.read()
    uploaded_file.seek(0)
    
    ext = uploaded_file.name.lower().split(".")[-1]
    engine = "openpyxl"
    if ext == "xls":
        engine = "xlrd"

    # header=Noneìœ¼ë¡œ ì½ì–´ì„œ ìœ„ì¹˜ ê¸°ë°˜ ì²˜ë¦¬ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•¨
    dfs = pd.read_excel(
        io.BytesIO(file_bytes),
        sheet_name=None,
        header=None,
        engine=engine
    )
    return dfs


def get_dataframe_preview_markdown(df: pd.DataFrame, rows: int = 20) -> str:
    """LLMì—ê²Œ ë³´ì—¬ì¤„ DataFrameì˜ Markdown í‘œí˜„"""
    preview_df = df.head(rows).copy()
    # Arrow ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ ë¬¸ìì—´ë¡œ ë³€í™˜
    return preview_df.fillna("").astype(str).to_markdown(index=True)


def extract_python_code(text: str) -> str:
    """ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì—ì„œ íŒŒì´ì¬ ì½”ë“œë§Œ ì¶”ì¶œ"""
    if "```python" in text:
        start = text.find("```python") + len("```python")
        end = text.find("```", start)
        if end == -1:
            return text[start:].strip()
        return text[start:end].strip()
    elif "```" in text:
        start = text.find("```") + 3
        end = text.find("```", start)
        if end == -1:
            return text[start:].strip()
        return text[start:end].strip()
    return text.strip()


def extract_json_block(text: str) -> str:
    """ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ í˜¹ì€ í…ìŠ¤íŠ¸ì—ì„œ JSON ì¶”ì¶œ"""
    if "```json" in text:
        start = text.find("```json") + len("```json")
        end = text.find("```", start)
        if end == -1:
            return text[start:].strip()
        return text[start:end].strip()
    
    # JSON ë¸”ë¡ì´ ëª…ì‹œì ì´ì§€ ì•Šì€ ê²½ìš° { } ì°¾ê¸°
    start = text.find("{")
    end = text.rfind("}")
    if start != -1 and end != -1:
        return text[start:end+1]
    return text


def safe_dataframe_display(df: pd.DataFrame, height: int = None):
    """
    st.dataframeì„ ì•ˆì „í•˜ê²Œ ë Œë”ë§í•˜ëŠ” ë˜í¼.
    Arrow Serialization ì—ëŸ¬ ë°œìƒ ì‹œ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì¬ì‹œë„.
    """
    kwargs = {}
    if height is not None:
        kwargs["height"] = height

    try:
        st.dataframe(df, **kwargs)
    except Exception as e:
        st.warning(f"âš ï¸ ê¸°ë³¸ ë°ì´í„°í”„ë ˆì„ ë Œë”ë§ ì‹¤íŒ¨ (Arrow í˜¸í™˜ì„± ë¬¸ì œ). í…ìŠ¤íŠ¸ ëª¨ë“œë¡œ í‘œì‹œí•©ë‹ˆë‹¤. ì—ëŸ¬: {e}")
        try:
            st.dataframe(df.astype(str), **kwargs)
        except Exception as e2:
            st.error(f"âŒ ë°ì´í„° í‘œì‹œ ì‹¤íŒ¨: {e2}")
            st.code(str(df.head(20)))  # ìµœí›„ì˜ ìˆ˜ë‹¨: repr ë¬¸ìì—´ ì¶œë ¥


# ==============================================================================
# 2. LLM ë¡œì§ (Schema ì„¤ê³„ + Code Gen)
# ==============================================================================

def generate_target_schema(api_key: str, all_previews: List[str]) -> Dict[str, Any]:
    """
    ì—¬ëŸ¬ íŒŒì¼ì˜ í”„ë¦¬ë·°ë¥¼ ë³´ê³  ê³µí†µ ëª©í‘œ ìŠ¤í‚¤ë§ˆ(Target Schema)ë¥¼ ì œì•ˆ
    """
    client = genai.Client(api_key=api_key)
    
    previews_text = "\n\n".join([f"--- File Sample {i+1} ---\n{p}" for i, p in enumerate(all_previews[:3])])

    prompt = f"""
ë‹¹ì‹ ì€ ë°ì´í„° ì•„í‚¤í…íŠ¸ì…ë‹ˆë‹¤. ì—¬ëŸ¬ ê°œì˜ ë¹„ì •í˜• ì—‘ì…€ íŒŒì¼ë“¤ì„ ë¶„ì„í•˜ì—¬ í•˜ë‚˜ë¡œ í†µí•©í•˜ê¸° ìœ„í•œ 'ê³µí†µ íƒ€ê²Ÿ ìŠ¤í‚¤ë§ˆ(Target Schema)'ë¥¼ ì„¤ê³„í•´ì•¼ í•©ë‹ˆë‹¤.

ëª©í‘œ:
1. ëª¨ë“  íŒŒì¼ì—ì„œ ê³µí†µì ìœ¼ë¡œ ì¶”ì¶œ ê°€ëŠ¥í•œ í•µì‹¬ ë¶„ì„ í•­ëª©(ì»¬ëŸ¼)ì„ ì •ì˜í•˜ì„¸ìš”.
2. ì»¬ëŸ¼ëª…ì€ ì˜ë¬¸ ìŠ¤ë„¤ì´í¬ ì¼€ì´ìŠ¤(snake_case)ë¡œ í†µì¼í•˜ì„¸ìš”.
3. ê° ì»¬ëŸ¼ì˜ ë°ì´í„° íƒ€ì…ê³¼ ì„¤ëª…ì„ í¬í•¨í•˜ì„¸ìš”.

ì…ë ¥ ë°ì´í„° ìƒ˜í”Œ:
{previews_text}

ì‘ë‹µ í˜•ì‹ (JSON):
```json
{{
    "table_name": "integrated_data",
    "columns": [
        {{"name": "region", "type": "string", "description": "ì§€ì—­ëª…"}},
        {{"name": "date", "type": "date", "description": "ê¸°ì¤€ ì¼ì"}},
        {{"name": "population", "type": "int", "description": "ì¸êµ¬ ìˆ˜"}}
    ]
}}
```
ë°˜ë“œì‹œ ìœ„ JSON í˜•ì‹ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""
    resp = client.models.generate_content(
        model="gemini-3-pro-preview",
        contents=prompt,
    )
    
    text = resp.text
    try:
        return json.loads(extract_json_block(text))
    except json.JSONDecodeError as e:
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì •ë³´ë¥¼ ë‹´ì•„ ë¦¬í„´ (UIì—ì„œ ì²˜ë¦¬)
        return {"columns": [], "_error": f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}", "_raw_response": text}
    except Exception as e:
        return {"columns": [], "_error": f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}", "_raw_response": text}


def generate_transform_code(
    api_key: str, 
    file_name: str, 
    sheet_name: str, 
    df_preview: str,
    target_columns: List[str]
) -> str:
    """
    Raw Data -> Target Schemaë¡œ ë³€í™˜í•˜ëŠ” íŒŒì´ì¬ ì½”ë“œ ì‘ì„±
    """
    client = genai.Client(api_key=api_key)
    
    target_cols_str = ", ".join([f"'{c}'" for c in target_columns])
    
    system_instruction = f"""
ë‹¹ì‹ ì€ Python Pandas ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
Raw Excel Dataë¥¼ ì •ì œí•˜ì—¬, ë°˜ë“œì‹œ **[Target Schema]**ì— ì •ì˜ëœ ì»¬ëŸ¼ì„ ê°€ì§„ DataFrameìœ¼ë¡œ ë³€í™˜í•˜ëŠ” `transform(df)` í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

### í•„ìˆ˜ ìš”êµ¬ì‚¬í•­
1. **í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜**: `def transform(df: pd.DataFrame) -> (pd.DataFrame, dict):`
2. **Target Schema ì¤€ìˆ˜**: ë°˜í™˜ë˜ëŠ” `df_clean`ì€ ë‹¤ìŒ ì»¬ëŸ¼ë“¤ì„ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤: [{target_cols_str}]
   - ë°ì´í„°ì— í•´ë‹¹ ì •ë³´ê°€ ì—†ë‹¤ë©´ `None`ì´ë‚˜ ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ìš°ì„¸ìš”.
   - ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ì€ ê³¼ê°íˆ ë²„ë¦¬ì„¸ìš”.
3. **ë©”íƒ€ë°ì´í„°**: ì œëª©, ë‹¨ìœ„ ë“±ì€ ë³„ë„ dictë¡œ ë°˜í™˜.
4. **ì „ì²˜ë¦¬**: 
   - í—¤ë” íƒìƒ‰, ë¶ˆí•„ìš”í•œ ìƒë‹¨ í–‰ ì œê±°
   - 'í•©ê³„', 'ì†Œê³„' ë“± í†µê³„ í–‰ ì œê±°
   - Wide to Long (Melt) ë³€í™˜ ì ê·¹ í™œìš©

### ì¶œë ¥ í˜•ì‹
ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ëŸ­(```python ... ```) ì•ˆì— íŒŒì´ì¬ ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.

### ì½”ë“œ í…œí”Œë¦¿
```python
import pandas as pd
import numpy as np

def transform(df):
    metadata = {{}}
    
    # 1. ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    # ...
    
    # 2. í—¤ë” ì°¾ê¸° ë° ë°ì´í„° ìŠ¬ë¼ì´ì‹±
    # ...
    
    # 3. ì»¬ëŸ¼ ë§¤í•‘ ë° ë°ì´í„° ì •ì œ
    # ...
    
    # 4. Target Schema ë§ì¶”ê¸° (í•„ìˆ˜ ë‹¨ê³„)
    # í•„ìš”í•œ ì»¬ëŸ¼ ìƒì„± ë° ì„ íƒ
    # df_clean = ...
    
    return df_clean, metadata
```
"""

    prompt = f"""
### ì²˜ë¦¬í•  íŒŒì¼
* íŒŒì¼: {file_name} / ì‹œíŠ¸: {sheet_name}

### ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
```markdown
{df_preview}
```

ìœ„ ë°ì´í„°ë¥¼ [{target_cols_str}] ì»¬ëŸ¼ì„ ê°€ì§„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

    resp = client.models.generate_content(
        model="gemini-3-pro-preview",
        contents=system_instruction + "\n" + prompt,
    )
    
    return extract_python_code(resp.text)


# ==============================================================================
# 3. ì½”ë“œ ì‹¤í–‰ê¸°
# ==============================================================================


def execute_user_code(code_str: str, df_raw: pd.DataFrame) -> Tuple[Optional[pd.DataFrame], Optional[Dict], str]:
    local_scope = {"pd": pd, "df_raw": df_raw, "np": pd.np} 
    
    try:
        exec(code_str, globals(), local_scope)
        if "transform" not in local_scope:
            return None, None, "Error: 'transform' í•¨ìˆ˜ê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            
        transform_func = local_scope["transform"]
        df_clean, metadata = transform_func(df_raw.copy())
        
        if not isinstance(df_clean, pd.DataFrame):
            return None, None, "Error: ë°˜í™˜ê°’ì€ DataFrameì´ì–´ì•¼ í•©ë‹ˆë‹¤."
            
        return df_clean, metadata, ""
        
    except Exception:
        return None, None, traceback.format_exc()


# ==============================================================================
# 4. Streamlit UI
# ==============================================================================


def main_app():
    st.set_page_config(page_title="AI í†µí•© ë°ì´í„° ì •ì œê¸°", layout="wide")
    st.title("ğŸ§© AI í†µí•© ë°ì´í„° ì •ì œê¸° (Many to One)")
    st.markdown("""
    ì—¬ëŸ¬ ê°œì˜ **ë¹„ì •í˜• ì—‘ì…€ íŒŒì¼**ì„ AIê°€ ì‘ì„±í•œ ì½”ë“œë¥¼ í†µí•´ **í•˜ë‚˜ì˜ í†µì¼ëœ CSV**ë¡œ í•©ì¹©ë‹ˆë‹¤.
    1. AIê°€ ê³µí†µ ìŠ¤í‚¤ë§ˆ(Target Schema)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
    2. ê° íŒŒì¼ë³„ë¡œ ìŠ¤í‚¤ë§ˆì— ë§ì¶”ëŠ” ë³€í™˜ ì½”ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    3. ê²°ê³¼ë¥¼ í•˜ë‚˜ë¡œ ë³‘í•©í•˜ì—¬ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    """)

    # --- ì„¤ì • ---
    st.sidebar.header("ì„¤ì •")
    api_key = st.sidebar.text_input("Gemini API Key", type="password")
    if not api_key:
        api_key = os.environ.get("GEMINI_API_KEY")
    
    uploaded_files = st.sidebar.file_uploader(
        "ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ (ì—¬ëŸ¬ ê°œ)", type=["xls", "xlsx"], accept_multiple_files=True
    )

    if not api_key:
        st.warning("Gemini API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return
        
    # Session State ì´ˆê¸°í™”
    if "target_schema" not in st.session_state:
        st.session_state["target_schema"] = {"columns": []}
    if "generated_codes" not in st.session_state:
        st.session_state["generated_codes"] = {}
    if "results" not in st.session_state:
        st.session_state["results"] = {}

    # 1. íŒŒì¼ ë¡œë”©
    all_data = {}
    if uploaded_files:
        for uf in uploaded_files:
            try:
                dfs = read_excel_sheets(uf)
                for sname, df in dfs.items():
                    all_data[(uf.name, sname)] = df
            except Exception as e:
                st.sidebar.error(f"{uf.name} ë¡œë“œ ì‹¤íŒ¨: {e}")
                with st.sidebar.expander("ìƒì„¸ ì—ëŸ¬"):
                    st.code(traceback.format_exc())

    if not all_data:
        st.info("íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return

    # 2. íƒ€ê²Ÿ ìŠ¤í‚¤ë§ˆ ì •ì˜
    st.header("1ï¸âƒ£ ê³µí†µ íƒ€ê²Ÿ ìŠ¤í‚¤ë§ˆ (Target Schema) ì •ì˜")
    
    col1, col2 = st.columns([1, 3])
    with col1:
        if st.button("ğŸ¤– AI ìŠ¤í‚¤ë§ˆ ìë™ ì œì•ˆ"):
            with st.spinner("ë°ì´í„° ìƒ˜í”Œ ë¶„ì„ ì¤‘..."):
                samples = []
                for k, df in list(all_data.items())[:3]:
                    samples.append(get_dataframe_preview_markdown(df, rows=10))
                
                schema_def = generate_target_schema(api_key, samples)
                
                # ì—ëŸ¬ ì²´í¬
                if "_error" in schema_def:
                    st.error("ìŠ¤í‚¤ë§ˆ ìƒì„± ì‹¤íŒ¨")
                    st.error(schema_def["_error"])
                    with st.expander("AI ì›ë³¸ ì‘ë‹µ"):
                        st.text(schema_def.get("_raw_response", ""))
                else:
                    st.session_state["target_schema"] = schema_def

    with col2:
        current_schema = st.session_state.get("target_schema")
        if current_schema is None:
            current_schema = {"columns": []}
            
        schema_text = st.text_area(
            "ìŠ¤í‚¤ë§ˆ ì •ì˜ (JSON í¸ì§‘ ê°€ëŠ¥)", 
            value=json.dumps(current_schema, indent=2, ensure_ascii=False),
            height=200
        )
        try:
            parsed = json.loads(schema_text)
            if isinstance(parsed, dict):
                st.session_state["target_schema"] = parsed
        except Exception as e:
            st.error(f"JSON í˜•ì‹ ì˜¤ë¥˜: {e}")

    schema = st.session_state.get("target_schema")
    if not isinstance(schema, dict):
        schema = {"columns": []}
    
    target_columns = [c["name"] for c in schema.get("columns", []) if isinstance(c, dict) and "name" in c]
    
    if not target_columns:
        st.warning("ìœ„ì—ì„œ íƒ€ê²Ÿ ìŠ¤í‚¤ë§ˆë¥¼ ì •ì˜í•˜ê±°ë‚˜ AI ì œì•ˆì„ ë°›ì•„ì£¼ì„¸ìš”.")
        return

    st.success(f"ëª©í‘œ ì»¬ëŸ¼: {target_columns}")

    # 3. ê°œë³„ íŒŒì¼ ë³€í™˜ ì½”ë“œ ìƒì„± ë° ì‹¤í–‰
    st.header("2ï¸âƒ£ íŒŒì¼ë³„ ë³€í™˜ ë° ë³‘í•©")
    
    tabs = st.tabs([f"{f}::{s}" for f, s in all_data.keys()])
    
    valid_dfs = []

    for i, (key, df_raw) in enumerate(all_data.items()):
        fname, sname = key
        unique_id = f"{fname}::{sname}"
        
        with tabs[i]:
            c1, c2 = st.columns([1, 1])
            
            # ì½”ë“œ ìƒì„±
            with c1:
                st.markdown("#### Raw Data Preview")
                # ì•ˆì „í•œ ë Œë”ë§ ì‚¬ìš© (Raw ë°ì´í„°ëŠ” ë³´í†µ íƒ€ì…ì´ ì„ì—¬ ìˆìœ¼ë¯€ë¡œ ì£¼ì˜ í•„ìš”)
                safe_dataframe_display(df_raw.head(15))
                
                if st.button(f"ì½”ë“œ ìƒì„± ({sname})", key=f"gen_{unique_id}"):
                    with st.spinner("ë³€í™˜ ì½”ë“œ ì‘ì„± ì¤‘..."):
                        preview = get_dataframe_preview_markdown(df_raw)
                        code = generate_transform_code(api_key, fname, sname, preview, target_columns)
                        st.session_state["generated_codes"][unique_id] = code
                        st.rerun()
            
            # ì½”ë“œ ì‹¤í–‰
            with c2:
                st.markdown("#### Transformation Code")
                code_val = st.session_state["generated_codes"].get(unique_id, "")
                edited_code = st.text_area("Python Code", code_val, height=300, key=f"edit_{unique_id}")
                st.session_state["generated_codes"][unique_id] = edited_code
                
                if st.button(f"ì‹¤í–‰ ({sname})", key=f"exec_{unique_id}"):
                    df_res, meta, err = execute_user_code(edited_code, df_raw)
                    if err:
                        st.error("ì½”ë“œ ì‹¤í–‰ ì˜¤ë¥˜")
                        st.code(err, language="text")
                    else:
                        # ìŠ¤í‚¤ë§ˆ ê²€ì¦
                        missing = [c for c in target_columns if c not in df_res.columns]
                        if missing:
                            st.warning(f"âš ï¸ ì£¼ì˜: ëª©í‘œ ì»¬ëŸ¼ ëˆ„ë½ -> {missing}")
                        else:
                            # ì»¬ëŸ¼ ìˆœì„œ ì •ë ¬
                            df_res = df_res[target_columns] 
                            
                            df_res["_source_file"] = fname
                            df_res["_source_sheet"] = sname
                            
                            st.session_state["results"][unique_id] = df_res
                            st.success("ë³€í™˜ ì„±ê³µ!")
                            safe_dataframe_display(df_res.head(5))
                            st.rerun()

        if unique_id in st.session_state["results"]:
            valid_dfs.append(st.session_state["results"][unique_id])

    # 4. ìµœì¢… ë³‘í•© ë° ë‹¤ìš´ë¡œë“œ
    st.divider()
    st.header("3ï¸âƒ£ ìµœì¢… ë³‘í•© ë° ë‹¤ìš´ë¡œë“œ")
    
    if valid_dfs:
        try:
            final_df = pd.concat(valid_dfs, ignore_index=True)
            st.markdown(f"### ğŸ“¦ ì´ {len(valid_dfs)}ê°œ íŒŒì¼ ë³‘í•© ì™„ë£Œ ({len(final_df)} í–‰)")
            safe_dataframe_display(final_df.head(20))
            
            csv_bytes = final_df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ğŸ“¥ í†µí•© CSV ë‹¤ìš´ë¡œë“œ",
                data=csv_bytes,
                file_name="merged_data.csv",
                mime="text/csv"
            )
        except Exception as e:
            st.error("ë³‘í•© ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
            st.code(traceback.format_exc())
    else:
        st.info("ì•„ì§ ë³€í™˜ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê° íƒ­ì—ì„œ ì½”ë“œë¥¼ ìƒì„±í•˜ê³  ì‹¤í–‰í•´ì£¼ì„¸ìš”.")


def main():
    try:
        main_app()
    except Exception as e:
        st.error("ğŸš¨ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘ ì˜ˆê¸°ì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        st.error(str(e))
        with st.expander("ìƒì„¸ ì˜¤ë¥˜ ë¡œê·¸ (Traceback)"):
            st.code(traceback.format_exc())


if __name__ == "__main__":
    main()
